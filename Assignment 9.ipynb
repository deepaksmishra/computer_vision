{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What are the advantages of a CNN for image classification over a completely linked DNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592527e",
   "metadata": {},
   "source": [
    "CNN's layers are only partially connnected and reuses its weights.\n",
    "learned a kernel which can detect a particular features.\n",
    "A CNN's architecture embeds this prior knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ed3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Consider a CNN with three convolutional layers, each of which has three kernels, a stride of two,\n",
    "and SAME padding. The bottom layer generates 100 function maps, the middle layer 200, and the\n",
    "top layer 400. RGB images with a size of 200 x 300 pixels are used as input. How many criteria does\n",
    "the CNN have in total? How much RAM would this network need when making a single instance\n",
    "prediction if we&#39;re using 32-bit floats? What if you were to practice on a batch of 50 images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d2ac1",
   "metadata": {},
   "source": [
    "\n",
    "first convolutional layer kernel-size and RGB channels, plus bias: 3 * 3 * 3 + 1 = 28 output feature maps is 100: 28 * 100 = 2800\n",
    "second convolutional layer kernel-size and last feature maps, plus bias: 3 * 3 * 100 + 1 = 901 output feature maps is 200: 901 * 200 = 180200\n",
    "third convolutional layers kernel-size and last feautre maps, plus bias: 3 * 3 * 200 + 1 =1801 output feautre maps is 400: 1801 * 400 = 720400\n",
    "Total parameters is 2800 + 180200 + 720400 = 903400\n",
    "\n",
    "memories since 32-bit is 4 bytes\n",
    "\n",
    "first convolutional layer one feature map size: 100 * 150 = 15000 total output: 15000 * 100 = 1,500,000\n",
    "second convolutional layer one feature map size: 50 * 75 = 3,750 total output: 3750 * 200 = 750,000\n",
    "third convolutional layer one feature map size: 25 * 38 = 950 total ouput: 950 * 400 = 380, 000\n",
    "(1,500,000 + 750,000 + 380,000) * 4 / 1024 /1024 = 10.032 (MB) 903400 * 4 / 1024 / 1024 = 3.44 (MB) 10.032+ 3.44=13.47(MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99cda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What are five things you might do to fix the problem if your GPU runs out of memory while\n",
    "training a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152efcc",
   "metadata": {},
   "source": [
    "reduce mini-batch size\n",
    "reduce dimensionality using a larger stride in one or more layers\n",
    "remove one or more layers\n",
    "using 16-bits instead of 32-bit floats\n",
    "distributed the cnn across multiple devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Why would you use a max pooling layer instead with a convolutional layer of the same stride?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383f774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. When would a local response normalization layer be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab57e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. In comparison to LeNet-5, what are the main innovations in AlexNet? What about GoogLeNet and\n",
    "ResNet&#39;s core innovations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6b039",
   "metadata": {},
   "source": [
    "AlexNet\n",
    "it is much larger and deeper\n",
    "stacks convolutional layer directly on top of each convlutional layer\n",
    "\n",
    "GooLeNet\n",
    "introduce a inception modules, which make it possible to have much deeper net than previous network\n",
    "\n",
    "ResNet\n",
    "introduce a skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3dafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. On MNIST, build your own CNN and strive to achieve the best possible accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6dcbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Using Inception v3 to classify broad images. a.\n",
    "Images of different animals can be downloaded. Load them in Python using the\n",
    "matplotlib.image.mpimg.imread() or scipy.misc.imread() functions, for example. Resize and/or crop\n",
    "them to 299 x 299 pixels, and make sure they only have three channels (RGB) and no transparency.\n",
    "The photos used to train the Inception model were preprocessed to have values ranging from -1.0 to\n",
    "1.0, so make sure yours do as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97865e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Large-scale image recognition using transfer learning.\n",
    "a. Make a training set of at least 100 images for each class. You might, for example, identify your\n",
    "own photos based on their position (beach, mountain, area, etc.) or use an existing dataset, such as\n",
    "the flowers dataset or MIT&#39;s places dataset (requires registration, and it is huge).\n",
    "b. Create a preprocessing phase that resizes and crops the image to 299 x 299 pixels while also\n",
    "adding some randomness for data augmentation.\n",
    "c. Using the previously trained Inception v3 model, freeze all layers up to the bottleneck layer (the\n",
    "last layer before output layer) and replace output layer with appropriate number of outputs for\n",
    "your new classification task (e.g., the flowers dataset has five mutually exclusive classes so the\n",
    "output layer must have five neurons and use softmax activation function).\n",
    "d. Separate the data into two sets: a training and a test set. The training set is used to train the\n",
    "model, and the test set is used to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9488f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccf5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b25c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
