{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "computer_vision_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GGZ6o43ITkb"
      },
      "source": [
        "1. Explain convolutional neural network, and how does it work?\n",
        "Ans: \n",
        "\n",
        "A Convolutional Neural Network, also known as CNN or ConvNet, is a class of neural networks that specializes in processing data that has a grid-like topology, such as an image. \n",
        "Each neuron works in its own receptive field and is connected to other neurons in a way that they cover the entire visual field\n",
        "\n",
        "2. How does refactoring parts of your neural network definition favor you?\n",
        "Ans: \n",
        "A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, either organic or artificial in nature. Neural networks can adapt to changing input; so the network generates the best possible result without needing to redesign the output criteria. The concept of neural networks, which has its roots in artificial intelligence, is swiftly gaining popularity in the development of trading systems.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason for this?\n",
        "Ans: \n",
        "To sum up, here is what we have after we're done with each of the steps that we have covered up until now:\n",
        "\n",
        "Input image (starting point)\n",
        "Convolutional layer (convolution operation)\n",
        "Pooling layer (pooling)\n",
        "Input layer for the artificial neural network (flattening)\n",
        "\n",
        "\n",
        "\n",
        "4. What exactly does NCHW stand for?\n",
        "Ans: \n",
        "\n",
        "NCHW stands for:\n",
        "\n",
        "batch N, channels C, depth D, height H, width W\n",
        "\n",
        "It is a way to store multidimensional arrays / data frames / matrix into memory, which can be considered as a 1-D array. You may have a look to this link for further information. There also exist variants of this format with different ways of \"casting\" the multidimensional data into one.\n",
        "\n",
        "\n",
        "5. Why are there 7*7*(1168-16) multiplications in the MNIST CNN's third layer?\n",
        "Ans: We present Chameleon, a novel hybrid (mixed-protocol) framework for secure function evaluation (SFE) which enables two parties to jointly compute a function without disclosing their private inputs. Chameleon combines the best aspects of generic SFE protocols with the ones that are based upon additive secret sharing. In particular, the framework per...\n",
        "\n",
        "\n",
        "\n",
        "6.Explain definition of  receptive field?\n",
        "Ans: \n",
        "While deep neural networks have overwhelmingly established state-of-the-art results in many artificial intelligence problems, they can still be difficult to develop and debug. Recent research on deep learning understanding has focused on feature visualization \n",
        "[1, 2]\n",
        ", theoretical guarantees \n",
        "[3, 4]\n",
        ", model interpretability \n",
        "[5, 6]\n",
        ", and generalization \n",
        "[7, 8]\n",
        ".\n",
        "\n",
        "In this work, we analyze deep neural networks from a complementary perspective, focusing on convolutional models. We are interested in understanding the extent to which input signals may affect output features, and mapping features at any part of the network to the region in the input that produces them. The key parameter to associate an output feature to an input region is the receptive field of the convolutional network, which is defined as the size of the region in the input that produces the feature.\n",
        "\n",
        "\n",
        "7. What is the scale of an activation's receptive field after two stride-2 convolutions? What is the reason for this?\n",
        "Ans: \n",
        "Towards Data Science\n",
        "\n",
        "\n",
        "Upgrade\n",
        "\n",
        "Follow\n",
        "599K Followers\n",
        "·\n",
        "Editors' Picks\n",
        "Features\n",
        "Deep Dives\n",
        "Grow\n",
        "Contribute\n",
        "About\n",
        "\n",
        "\n",
        "Intuitively Understanding Convolutions for Deep Learning\n",
        "Exploring the strong visual hierarchies that makes them work\n",
        "Irhum Shafkat\n",
        "Irhum Shafkat\n",
        "\n",
        "Jun 2, 2018·15 min read\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The advent of powerful and versatile deep learning frameworks in recent years has made it possible to implement convolution layers into a deep learning model an extremely simple task, often achievable in a single line of code.\n",
        "However, understanding convolutions, especially for the first time can often feel a bit unnerving, with terms like kernels, filters, channels and so on all stacked onto each other. Yet, convolutions as a concept are fascinatingly powerful and highly extensible, and in this post, we’ll break down the mechanics of the convolution operation, step-by-step, relate it to the standard fully connected network, and explore just how they build up a strong visual hierarchy, making them powerful feature extractors for images.\n",
        "\n",
        "\n",
        "8. What is the tensor representation of a color image?\n",
        "Ans: \n",
        "The RGB color image is seen as a 3rd-order tensor to exploit the spatial and interchannel correlation, so that blurring effects are captured more robustly. The tensor is decomposed into different two-dimensional matrices,\n",
        "\n",
        "\n",
        "9. How does a color input interact with a convolution?\n",
        "Ans: \n",
        "A convolution is the simple application of a filter to an input that results in an activation. Repeated application of the same filter to an input results in a map of activations called a feature map, indicating the locations and strength of a detected feature in an input, such as an image.\n",
        "\n",
        "The innovation of convolutional neural networks is the ability to automatically learn a large number of filters in parallel specific to a training dataset under the constraints of a specific predictive modeling problem, such as image classification. The result is highly specific features that can be detected anywhere on input images.\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}